{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c71afd3",
   "metadata": {},
   "source": [
    "### Exercise 1. Loading json files with pandas. Reading data is the first step in any data science project. Often, you’ll work with data in json format and run into problems at the very beginning. The Python libraries json and pandas work for the user. This exercise requires the user to solve two common issues when loading a json file to a data frame. Follow the instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c9b14",
   "metadata": {},
   "source": [
    "***c. Load the 01-call_logs.json file to the 00-load notebook.***\n",
    "\n",
    "- Explore the json file to infer better the loading strategy \n",
    "> By visual inspection, the JSON file has a dictionary-like structure, with each entry consistent of a single element\n",
    "\n",
    "- Use pandas read_json() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12996896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "call_logs_01 = pd.read_json('../data/raw/01-call_logs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe80a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                start_date  abandon  prequeue  inqueue  agent_time  postqueue  \\\n",
      "0      2019-01-01 00:00:00        1         5      153           0          0   \n",
      "1      2019-01-28 16:43:00        1       233        0           0          0   \n",
      "2      2019-01-31 11:36:00        0        12        0        1018          1   \n",
      "3      2019-01-17 13:23:00        0         6        4         114          0   \n",
      "4      2019-01-22 13:58:00        0         5       51         141          0   \n",
      "...                    ...      ...       ...      ...         ...        ...   \n",
      "31594  2019-01-07 09:12:00        0         6      105         275          0   \n",
      "31595  2019-01-29 09:37:00        0        13        0         314          0   \n",
      "31596  2019-01-22 11:39:00        0         6       65         178          0   \n",
      "31597  2019-01-15 12:06:00        0        10        0           2          0   \n",
      "31598  2019-01-17 17:46:00        1         9       15           0          0   \n",
      "\n",
      "       total_time  sla    contact_id     master_id  ... cont_name  \\\n",
      "0               0  NaN  03143753e587  22143753e587  ...      Luís   \n",
      "1               0  NaN  0314375387fe  2214375387fe  ...     Laura   \n",
      "2            1031  1.0  03143753f3f7  22143753f3f7  ...  Apolonia   \n",
      "3             124  1.0  03143753ddc8  22143753ddc8  ...   Matthew   \n",
      "4             197  1.0  031437531bf4  221437531bf4  ...    Filipa   \n",
      "...           ...  ...           ...           ...  ...       ...   \n",
      "31594         386  1.0  03143753c1df  22143753c1df  ...    Niklas   \n",
      "31595         327  1.0  03143753dcf6  22143753dcf6  ...    Krista   \n",
      "31596         249  1.0  03143753fecd  22143753fecd  ...    Manuel   \n",
      "31597          12  1.0  03143753a242  22143753a242  ...      Paul   \n",
      "31598           0  NaN  031437535e99  221437535e99  ...     Elisa   \n",
      "\n",
      "      cont_last_name                  cont_email     cont_phone  \\\n",
      "0          Rodrigues          zsousa@example.net  6185826945946   \n",
      "1          Fonjallaz            krey@example.org  5680228173015   \n",
      "2           Fornalik     soniaanders@example.net  9491982173163   \n",
      "3              Pitts   petersonerica@example.net  8902555276493   \n",
      "4            Pacheco          vpinto@example.com  5305081352875   \n",
      "...              ...                         ...            ...   \n",
      "31594         Börner     kathicaspar@example.com  4867162710313   \n",
      "31595          Fritz       suzanne88@example.com  2727985263337   \n",
      "31596          Jesus   coelholarissa@example.com  3759359915395   \n",
      "31597          Landl  marie-louise22@example.org  2213500790638   \n",
      "31598          Polla         wbeuret@example.com    11401164308   \n",
      "\n",
      "               cmpg_name  sent_name  chan_type chan_name chan_priority  \\\n",
      "0          Sales Army VI    sadness      voice      call             5   \n",
      "1            Deliverando    sadness      voice      call             5   \n",
      "2      Recruit FactorIII    sadness      voice      call             5   \n",
      "3       Recruit Factor V    sadness      voice      call             5   \n",
      "4            Deliverando    sadness      voice      call             5   \n",
      "...                  ...        ...        ...       ...           ...   \n",
      "31594       Sales Army V  gratitude       test   chatbot             3   \n",
      "31595  Recruit Factor VI  gratitude       test   chatbot             3   \n",
      "31596         Billings A  gratitude       test   chatbot             3   \n",
      "31597         Billings E  gratitude       test   chatbot             3   \n",
      "31598         Billings E  gratitude       test   chatbot             3   \n",
      "\n",
      "               rsn_name  \n",
      "0      technical issues  \n",
      "1      technical issues  \n",
      "2      technical issues  \n",
      "3      technical issues  \n",
      "4      technical issues  \n",
      "...                 ...  \n",
      "31594     service issue  \n",
      "31595     service issue  \n",
      "31596     service issue  \n",
      "31597     service issue  \n",
      "31598     service issue  \n",
      "\n",
      "[31599 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "print(call_logs_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c1c9cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5f353e4",
   "metadata": {},
   "source": [
    "- Test different parameters in the read_json() function\n",
    "\n",
    "> We may try different options to read_json. For example, we may load the entire json file as one line:\n",
    ">\n",
    "> `pd.read_json('../data/raw/01-call_logs.json', lines=True)`\n",
    ">\n",
    "> or a series:\n",
    ">\n",
    "> `pd.read_json('../data/raw/01-call_logs.json', typ='series')`\n",
    ">\n",
    "> We can also use to the function [`to_json()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html#pandas.DataFrame.to_json) to convert the dataframe into a json string, and then 'split' in a `dict` manner the columns, index and values:\n",
    ">\n",
    "> `pd.read_json('../data/raw/01-call_logs.json').to_json(orient='split')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a3c40",
   "metadata": {},
   "source": [
    "***d. Load the 02-call_logs.json file to the 00-load notebook.***\n",
    "\n",
    "- Explore the json file to infer better the loading strategy\n",
    "> By visual inspection, the JSON file has a nested dictionary-like structure with element 'call_logs \n",
    "\n",
    "- Use pandas read_json() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a1e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_logs_02 = pd.read_json('../data/raw/02-call_logs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aaea507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_cont  cont_name cont_last_name                  cont_email  \\\n",
      "0      10010027  Victorino         Tudela  domingocompany@example.net   \n",
      "1      10010027  Victorino         Tudela  domingocompany@example.net   \n",
      "2      10010027  Victorino         Tudela  domingocompany@example.net   \n",
      "3      10010027  Victorino         Tudela  domingocompany@example.net   \n",
      "4      10010027  Victorino         Tudela  domingocompany@example.net   \n",
      "...         ...        ...            ...                         ...   \n",
      "33339  Z999265T    Stewart          Davis    williamsiain@example.com   \n",
      "33340  Z999265T    Stewart          Davis    williamsiain@example.com   \n",
      "33341  Z999265T    Stewart          Davis    williamsiain@example.com   \n",
      "33342  Z999608T     Connor          Baker      morganglen@example.net   \n",
      "33343  Z999608T     Connor          Baker      morganglen@example.net   \n",
      "\n",
      "          cont_phone  id_agn agn_name  last_name  \\\n",
      "0       750144000000   12750   Elston     Howard   \n",
      "1       750144000000   13000     Raul   Gonzales   \n",
      "2       750144000000   13010    Fabio  Cannavaro   \n",
      "3       750144000000   13030  Ronaldo    de Asis   \n",
      "4       750144000000   13110   Hristo   Stoichov   \n",
      "...              ...     ...      ...        ...   \n",
      "33339   526051000000   12700     Phil    Rizzuto   \n",
      "33340   526051000000   12750   Elston     Howard   \n",
      "33341   526051000000   13110   Hristo   Stoichov   \n",
      "33342  6265210000000   12830    Aaron      Judge   \n",
      "33343  6265210000000   13040  Gabriel  Batistuta   \n",
      "\n",
      "                               agn_email     id_ccl  ...  id_rsn  \\\n",
      "0                  ehoward@nice.team.org  am_sam002  ...  bil-02   \n",
      "1       rgonzales@nice.international.org  am_nam023  ...  bil-04   \n",
      "2      fcannavaro@nice.international.org  am_nam023  ...  bil-03   \n",
      "3           rasis@nice.international.org  am_nam022  ...  bil-01   \n",
      "4       hstoichov@nice.international.org  am_nam022  ...  prd-03   \n",
      "...                                  ...        ...  ...     ...   \n",
      "33339             prizzuto@nice.team.org   eu-neu01  ...  ser-01   \n",
      "33340              ehoward@nice.team.org  am_nam001  ...  pri-01   \n",
      "33341   hstoichov@nice.international.org  am_nam001  ...  acc-01   \n",
      "33342               ajudge@nice.team.org  am_sam001  ...  ser-01   \n",
      "33343  gbatistuta@nice.international.org  am_nam003  ...  bil-01   \n",
      "\n",
      "                  rsn_name  id_team         team_name id_skill    skill_name  \\\n",
      "0         billing question    11201       Technocrats    20090       chatter   \n",
      "1       billing reschedule    11201       Technocrats    20090       chatter   \n",
      "2          billing payment    11202    The Front Line    20095       chatter   \n",
      "3      billing information    11204  Sultans of Sales    20075  multitasking   \n",
      "4          product service    11202    The Front Line    20100       chatter   \n",
      "...                    ...      ...               ...      ...           ...   \n",
      "33339        service issue    11201       Technocrats    20076  multitasking   \n",
      "33340              pricing    11201       Technocrats    20090       chatter   \n",
      "33341        account login    11202    The Front Line    20100       chatter   \n",
      "33342        service issue    11204  Sultans of Sales    20082      listener   \n",
      "33343  billing information    11205     The Brainiacs    20076  multitasking   \n",
      "\n",
      "      skill_disp_code skill_importance skill_sentiment  \\\n",
      "0                 120                3      Reflective   \n",
      "1                 120                3      Reflective   \n",
      "2                 121                4        Cheerful   \n",
      "3                 100                1        Cheerful   \n",
      "4                 122                5        Emphatic   \n",
      "...               ...              ...             ...   \n",
      "33339             103                3      Reflective   \n",
      "33340             120                3      Reflective   \n",
      "33341             122                5        Emphatic   \n",
      "33342             114                3      Reflective   \n",
      "33343             103                3      Reflective   \n",
      "\n",
      "                                                call_log  \n",
      "0      [{'contact_id': '03143748a367', 'master_id': '...  \n",
      "1      [{'contact_id': '03143749dfc1', 'master_id': '...  \n",
      "2      [{'contact_id': '0314374980cf', 'master_id': '...  \n",
      "3      [{'contact_id': '31437494967', 'master_id': '2...  \n",
      "4      [{'contact_id': '03143749e725', 'master_id': '...  \n",
      "...                                                  ...  \n",
      "33339  [{'contact_id': '031437483d2d', 'master_id': '...  \n",
      "33340  [{'contact_id': '03143749b0ef', 'master_id': '...  \n",
      "33341  [{'contact_id': '031437498f93', 'master_id': '...  \n",
      "33342  [{'contact_id': '031437491fca', 'master_id': '...  \n",
      "33343  [{'contact_id': '0314374986bc', 'master_id': '...  \n",
      "\n",
      "[33344 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(call_logs_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961ff6a",
   "metadata": {},
   "source": [
    "- Verify the nested list call_log inside the pandas dataframe\n",
    "> Already mentioned two bullet points above. This is also observed when printing call_logs_02 in the bullet point above.\n",
    "\n",
    "- Explore a method to flatten the json file when loading to pandas dataframe\n",
    "> To flatten a dataframe, we may first convert it to a numpy array using [`to_numpy()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_numpy.html) and then flatten it using [`flatten()`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee330aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10010027' 'Victorino' 'Tudela' ... 3 'Reflective'\n",
      " list([{'contact_id': '0314374986bc', 'master_id': '2214374986bc', 'start_date': '2/1/2019 20:48', 'abandon': 0, 'prequeue': 10, 'inqueue': 219, 'agent_time': 178, 'postqueue': 0, 'total_time': 407, 'sla': 1.0, 'abandon_time': 0, 'date': '2/1/2019', 'start_time': '20:48:00'}])]\n"
     ]
    }
   ],
   "source": [
    "print(call_logs_02.to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d69962",
   "metadata": {},
   "source": [
    "> In addition, we may also flatten the dataframe using the method described in point (c), by specifying `lines=True` in the parameters. For this case, we retain the dictionary-like structure with keys being shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd0286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               0      \\\n",
      "0  {'id_cont': '10010027', 'cont_name': 'Victorin...   \n",
      "\n",
      "                                               1      \\\n",
      "0  {'id_cont': '10010027', 'cont_name': 'Victorin...   \n",
      "\n",
      "                                               2      \\\n",
      "0  {'id_cont': '10010027', 'cont_name': 'Victorin...   \n",
      "\n",
      "                                               3      \\\n",
      "0  {'id_cont': '10010027', 'cont_name': 'Victorin...   \n",
      "\n",
      "                                               4      \\\n",
      "0  {'id_cont': '10010027', 'cont_name': 'Victorin...   \n",
      "\n",
      "                                               5      \\\n",
      "0  {'id_cont': '10010027', 'cont_name': 'Victorin...   \n",
      "\n",
      "                                               6      \\\n",
      "0  {'id_cont': '1005222', 'cont_name': 'Juan Anto...   \n",
      "\n",
      "                                               7      \\\n",
      "0  {'id_cont': '1005222', 'cont_name': 'Juan Anto...   \n",
      "\n",
      "                                               8      \\\n",
      "0  {'id_cont': '1005222', 'cont_name': 'Juan Anto...   \n",
      "\n",
      "                                               9      ...  \\\n",
      "0  {'id_cont': '1005222', 'cont_name': 'Juan Anto...  ...   \n",
      "\n",
      "                                               33334  \\\n",
      "0  {'id_cont': 'Z996370T', 'cont_name': 'Abigail'...   \n",
      "\n",
      "                                               33335  \\\n",
      "0  {'id_cont': 'Z998488T', 'cont_name': 'Georgina...   \n",
      "\n",
      "                                               33336  \\\n",
      "0  {'id_cont': 'Z998488T', 'cont_name': 'Georgina...   \n",
      "\n",
      "                                               33337  \\\n",
      "0  {'id_cont': 'Z998488T', 'cont_name': 'Georgina...   \n",
      "\n",
      "                                               33338  \\\n",
      "0  {'id_cont': 'Z999265T', 'cont_name': 'Stewart'...   \n",
      "\n",
      "                                               33339  \\\n",
      "0  {'id_cont': 'Z999265T', 'cont_name': 'Stewart'...   \n",
      "\n",
      "                                               33340  \\\n",
      "0  {'id_cont': 'Z999265T', 'cont_name': 'Stewart'...   \n",
      "\n",
      "                                               33341  \\\n",
      "0  {'id_cont': 'Z999265T', 'cont_name': 'Stewart'...   \n",
      "\n",
      "                                               33342  \\\n",
      "0  {'id_cont': 'Z999608T', 'cont_name': 'Connor',...   \n",
      "\n",
      "                                               33343  \n",
      "0  {'id_cont': 'Z999608T', 'cont_name': 'Connor',...  \n",
      "\n",
      "[1 rows x 33344 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_json('../data/raw/02-call_logs.json', lines=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb7beb",
   "metadata": {},
   "source": [
    "***e. Write a method wrapping the techniques of c. and d. above to load json files. For example, a method load_json() with parameters to load directly or flatten and load json files***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d98fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file, flat=False):\n",
    "    \"\"\"A method to return a JSON file\n",
    "        file: name of file with path included\n",
    "        flat: if True, it flattens the dataframe. Default is False\"\"\"\n",
    "\n",
    "    if flat is True:\n",
    "        return pd.read_json(file).to_numpy().flatten()\n",
    "    else:\n",
    "        return pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba9d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10010027' 'Victorino' 'Tudela' ... 3 'Reflective'\n",
      " list([{'contact_id': '0314374986bc', 'master_id': '2214374986bc', 'start_date': '2/1/2019 20:48', 'abandon': 0, 'prequeue': 10, 'inqueue': 219, 'agent_time': 178, 'postqueue': 0, 'total_time': 407, 'sla': 1.0, 'abandon_time': 0, 'date': '2/1/2019', 'start_time': '20:48:00'}])]\n"
     ]
    }
   ],
   "source": [
    "print(load_json('../data/raw/02-call_logs.json', flat=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d073ca",
   "metadata": {},
   "source": [
    "### Exercise 2. Loading data and save to parquet. Other common formats to store data are txt, csv, xlsx, and parquet. A challenge in Big Data is related to a variety of data, e.g., different formats. In this exercise, you create a method to read txt, csv, xlsx, and parquet files to a dataframe. Follow the steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebd79ab",
   "metadata": {},
   "source": [
    "***c. For each of the files with prefix 03-call_logs to 06-call_logs load the file to the 00-load notebook. Please observe the following:***\n",
    "\n",
    "- Explore the methods in pandas to load files based on their formats \n",
    "> To load parquet files, we may use [`read_parquet`](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html), for which we first need to install the packages `pyarrow` and `fastparquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e1fabd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (8.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from pyarrow) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fdcdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: fsspec in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from fastparquet) (2022.5.0)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from fastparquet) (2.5.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from fastparquet) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.18 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from fastparquet) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from pandas>=1.1.0->fastparquet) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->fastparquet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09e2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_logs_03 = pd.read_parquet('../data/raw/03-call_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021a185",
   "metadata": {},
   "source": [
    "> To load parquet files, we may use [`read_excel`](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html), for which we first need to install the package `openpyxl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "822e3fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /Users/juanrosas/opt/miniconda3/envs/dataingestion_env/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4e7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_logs_04 = pd.read_excel('../data/raw/04-call_logs.xlsx', sheet_name='call_logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c21a33",
   "metadata": {},
   "source": [
    "> To load txt files, we may use [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). By visual inspection, we noticed the txt file is comma-separated, so we may add the optional argument `delimiter=','` to properly load the data into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d7e4dd",
   "metadata": {},
   "source": [
    "> To load csv and txt files, we may use [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). By visual inspection, we noticed the txt file is comma-separated, so we may add the optional argument `delimiter=','` to properly load the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3dbeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_logs_05 = pd.read_csv('../data/raw/05-call_logs.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96e8e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_logs_06 = pd.read_csv('../data/raw/06-call_logs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da67a29",
   "metadata": {},
   "source": [
    "***d. Write a method to automatically load the call logs files. Do not miss the json file loader from exercise 1 to load the json files.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad8370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_call_logs(file, flat=False, sheet='call_logs'):\n",
    "    \"\"\"A method to load call_logs files of extension txt, cvs, xlsx, parquet or json\n",
    "        file: name of file with path included\n",
    "        flat: if True, it flattens the dataframe. Default is False\n",
    "        sheet: in case it is a csv or xlsx file, it specifies the sheet name. Default is 'call_logs'\"\"\"\n",
    "\n",
    "    if file.endswith('.txt'):\n",
    "        df = pd.read_csv(file, delimiter=',')\n",
    "    elif file.endswith('.csv'):\n",
    "        df = pd.read_csv(file)\n",
    "    elif file.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file, sheet_name=sheet)\n",
    "    elif file.endswith('.parquet'):\n",
    "        df = pd.read_parquet(file)\n",
    "    elif file.endswith('.json'):\n",
    "        df = pd.read_json(file)\n",
    "    else:\n",
    "        return 'Not a valid extension'\n",
    "\n",
    "    # Remove unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    # Flatten if flat=True\n",
    "    if flat is True:\n",
    "        return df.to_numpy().flatten()\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76eacb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
